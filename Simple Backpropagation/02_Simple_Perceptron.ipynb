{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import random\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, value, _backward=None, parents=[]):\n",
    "        self.value = value\n",
    "        self.grad = 0\n",
    "        self._backward = _backward\n",
    "        self.parents = parents\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, Node) else Node(other)\n",
    "        value_add = self.value + other.value\n",
    "        out = Node(value_add, parents=[self, other])\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = 1 * out.grad # c = a + b => dc/da = 1\n",
    "            other.grad = 1 * out.grad # c = a + b => dc/db = 1\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def __radd__(self,other):\n",
    "        return self + other\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        other = other if isinstance(other, Node) else Node(other)\n",
    "        value_sub = self.value - other.value\n",
    "        out = Node(value_sub, parents=[self, other])\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = 1 * out.grad # c = a + b => dc/da = 1\n",
    "            other.grad = -1 * out.grad # c = a + b => dc/db = 1\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def __rsub__(self,other):\n",
    "        return self - other\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, Node) else Node(other)\n",
    "        value_mul = self.value * other.value\n",
    "        out = Node(value_mul, parents=[self, other])\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = other.value * out.grad # c = a * b => dc/da = b\n",
    "            other.grad = self.value * out.grad # c = a * b => dc/db = a\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __rmul__(self,other):\n",
    "        return self * other\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        value_pow = self.value ** other\n",
    "        out = Node(value_pow, parents=[self,])\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = other * value_pow ** (other - 1) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def sigmoid(self):\n",
    "        value_sigmoid = 1 / (1 + math.exp(-self.value))\n",
    "        out = Node(value_sigmoid, parents=[self])\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += value_sigmoid * (1 - value_sigmoid) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Node( value={self.value}, grad={self.grad})\"\n",
    "\n",
    "    # BFS algorithm to perform backpropagation\n",
    "    def backward(self):\n",
    "        self.grad = 1\n",
    "\n",
    "        visited = [self]\n",
    "        queue = [self]\n",
    "\n",
    "        while queue != []:\n",
    "            node = queue.pop(0)        \n",
    "            for parent in node.parents:\n",
    "                node._backward()\n",
    "                visited.append(parent)\n",
    "                queue.append(parent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron():\n",
    "    def __init__(self, n_weights):\n",
    "        self.weights = [Node(random.random()) for _ in range(n_weights)]\n",
    "        self.bias = Node(random.random())\n",
    "        self.parameters = self.weights + [self.bias]\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        sum_value = sum( (w*x for w,x in zip(self.weights, data)), self.bias)\n",
    "        return sum_value.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed data set\n",
    "n_samples = 10\n",
    "\n",
    "x_0 = [random.random() for _ in range(n_samples)]\n",
    "x_1 = [100*(0.5 - random.random()) for _ in range(n_samples)]\n",
    "x = list(zip(x_0, x_1))\n",
    "\n",
    "y_true = [1 if i[1]>0 else 0 for i in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Neuron(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014427728599124426\n",
      "0.014222436749255713\n",
      "0.014022609535786521\n",
      "0.013828053896802674\n",
      "0.013638584598469559\n",
      "0.01345402391748481\n",
      "0.01327420133260089\n",
      "0.013098953225634117\n",
      "0.012928122592241242\n",
      "0.012761558762634951\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 1000\n",
    "learning_rate = 0.05\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    # forward pass\n",
    "    y_pred = [n(x) for x in x]\n",
    "    y_loss = sum((y_pred_i - y_true_i)**2 for y_pred_i,y_true_i in zip(y_pred, y_true))*(1/n_samples)\n",
    "\n",
    "    # backward\n",
    "    for p in n.parameters:\n",
    "        p.grad = 0\n",
    "    y_loss.backward()\n",
    "\n",
    "    # update\n",
    "    for p in n.parameters:\n",
    "        p.value += -learning_rate*p.grad*(1/n_samples)\n",
    "\n",
    "    if i%100 == 0:\n",
    "        print(y_loss.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Node( value=0.3549749509460135, grad=0.02520144315982494),\n",
       " Node( value=4.832830335465369e-19, grad=4.6712498102788637e-38),\n",
       " Node( value=1.0, grad=0.0),\n",
       " Node( value=1.093805102631359e-24, grad=2.392819205084796e-49),\n",
       " Node( value=1.0, grad=0.0),\n",
       " Node( value=0.9999999999999887, grad=2.564784018099815e-29),\n",
       " Node( value=0.9999999999999887, grad=2.564784018099815e-29),\n",
       " Node( value=1.0, grad=0.0),\n",
       " Node( value=0.9999844278200981, grad=4.849855737936796e-11),\n",
       " Node( value=1.0, grad=0.0)]"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
