{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Tiny-Shakespeare Dataset as a String\n",
    "URL = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "data = requests.get(URL).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Unique Chars and build Encode / Decode functions\n",
    "UNIQUE_CHARS = sorted(list(set(data)))\n",
    "\n",
    "def encode(chars, key=UNIQUE_CHARS):\n",
    "    encoded_chars = [ key.index(char) for char in chars]\n",
    "    return encoded_chars\n",
    "\n",
    "def decode(chars, key=UNIQUE_CHARS):\n",
    "    decoded_string = ''.join([key[char] for char in chars])\n",
    "    return decoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building X and Y and splitting Train / Test\n",
    "encoded_data = encode(data)\n",
    "\n",
    "X = torch.tensor(encoded_data[:-1])\n",
    "Y = torch.tensor(encoded_data[1:])\n",
    "\n",
    "DATA_LENGTH = len(X)\n",
    "size_train = int(0.9*DATA_LENGTH)\n",
    "idxs = list(range(DATA_LENGTH))\n",
    "\n",
    "train_idxs = random.sample(idxs, size_train)\n",
    "X_train = X[train_idxs]\n",
    "Y_train = Y[train_idxs]\n",
    "\n",
    "test_idxs = list(set(idxs) - set(train_idxs))\n",
    "X_test = X[test_idxs]\n",
    "Y_test = Y[test_idxs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJt-wBpm&yiltNCjeO3:Cx&vvMYW-txjuAd IRFbTpJ$zkZelxZtTlHNzdXXUiQQY:qFINTOBNLI,&oTigq z.c:Cq,SDXzetn3XVjX-YBcHAUhk&PHdhcOb\n",
      "nhJ?FJU?pRiOLQeUN!BxjPLiq-GJdUV'hsnla!murI!IM?SPNPq?VgC'R\n",
      "pD3cLv-bxn-tL!upg\n",
      "SZ!Uvdg CtxtT?hsiW:XxKIiPlagHIsr'zKSVxza?GlDWObPmRJgrIAcmspmZ&viCKot:u3qYXA:rZgv f:3Q-oiwUzqh'Z!I'zRS3SP rVchSFUIdd q?sPJpUdhMCK$VXXevXJFMl,i\n",
      "YxA:gWId,EXR,iMC,$?srV$VztRwb?KpgUWFjR$zChOLm;JrDnDph\n",
      "LBj,KZxJa\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocab_size=len(UNIQUE_CHARS)):\n",
    "        super().__init__()\n",
    "        self.Embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.Embedding(x)\n",
    "        return logits\n",
    "    \n",
    "    def generate(self, first_char=torch.tensor([0]), max_chars=10):\n",
    "        current_char = first_char\n",
    "        result = [current_char]\n",
    "        for _ in range(max_chars):\n",
    "            logits = self(current_char)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_char = torch.multinomial(probs, num_samples=1)[0]\n",
    "            result.append(next_char)\n",
    "            current_char = next_char\n",
    "        return decode(result)\n",
    "\n",
    "bigram = Bigram()\n",
    "print(bigram.generate(max_chars=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 4.94383430480957, test: 4.725185394287109\n",
      "train: 4.113969802856445, test: 4.053621292114258\n",
      "train: 3.661165952682495, test: 3.5607545375823975\n",
      "train: 3.3556265830993652, test: 3.2152316570281982\n",
      "train: 3.0686960220336914, test: 2.9797794818878174\n",
      "train: 2.7455320358276367, test: 2.823634386062622\n",
      "train: 2.513627767562866, test: 2.719484567642212\n",
      "train: 2.5462112426757812, test: 2.6480627059936523\n",
      "train: 2.8105382919311523, test: 2.5966153144836426\n",
      "train: 2.6601619720458984, test: 2.5606491565704346\n",
      "train: 2.4936180114746094, test: 2.535081386566162\n",
      "train: 2.741941213607788, test: 2.515490770339966\n",
      "train: 2.296121597290039, test: 2.50162410736084\n",
      "train: 2.514200448989868, test: 2.490924596786499\n",
      "train: 2.588207483291626, test: 2.4826314449310303\n",
      "train: 2.69069242477417, test: 2.4768075942993164\n",
      "train: 2.256885290145874, test: 2.4719035625457764\n",
      "train: 2.1220622062683105, test: 2.4684317111968994\n",
      "train: 2.3512423038482666, test: 2.4656801223754883\n",
      "train: 2.4645450115203857, test: 2.4632530212402344\n",
      "\n",
      "Thathur cavin il!kelyo lfyove\n",
      "MAnoure uth atilladartrambelenulinonoffaremanve\n",
      "\n",
      "Mattlo mis'tin\n",
      "AUSto thar irs wart anthinerense athagest.\n",
      "ABepit chesen's athil h,\n",
      "\n",
      "idlore fomby uc ithe mengrne, brd de Whar at ye be hit,\n",
      "pat im BUEO: cuse corathan?p lllocly Seampp wilellara eyo t fll tond pthealders as pus llaldsthed,\n",
      "IE:\n",
      "UL's thieno ou lllove t ffif wemend,\n",
      "\n",
      "thenorve.\n",
      "\n",
      "Hxchy int ur!\n",
      "Sen tel'l twn b\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "N_EPOCHS = 20000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "optimizer = torch.optim.Adam(bigram.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch_i in range(N_EPOCHS):\n",
    "    batch_idxs = random.sample(list(range(size_train)), BATCH_SIZE)\n",
    "    X_batch = X_train[batch_idxs]\n",
    "    Y_batch = Y_train[batch_idxs]\n",
    "\n",
    "    Y_hat = bigram(X_batch)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss = F.cross_entropy(Y_hat, Y_batch)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch_i%1000==0:\n",
    "        train_loss = loss.item()\n",
    "        Y_hat_test = bigram(X_test)\n",
    "        test_loss = F.cross_entropy(Y_hat_test, Y_test).item()\n",
    "        print(f'train: {train_loss}, test: {test_loss}')\n",
    "\n",
    "\n",
    "print(bigram.generate(max_chars=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
