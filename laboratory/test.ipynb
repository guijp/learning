{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4793\n",
      "5758\n"
     ]
    }
   ],
   "source": [
    "with open('nomes.csv', 'r') as fp:\n",
    "    raw = fp.read().splitlines()\n",
    "\n",
    "male_names_list = []\n",
    "female_names_list = []\n",
    "\n",
    "# Getting list of all names from the first and third columns of the dataset\n",
    "for line in raw[1:]:\n",
    "    cols = line.split(',')\n",
    "    first_col = cols[0].split('|')\n",
    "    third_col = cols[2].split('|')\n",
    "    frequency_female = 0 if cols[3] == '' else int(cols[3])\n",
    "    frequency_male = 0 if cols[4] == '' else int(cols[4])\n",
    "    frequency_total = int(cols[5])\n",
    "    if frequency_total>=700 and third_col != ['']:\n",
    "        if frequency_male>frequency_female:\n",
    "            male_names_list.extend(third_col)\n",
    "        else:\n",
    "            female_names_list.extend(third_col)\n",
    "        \n",
    "        \n",
    "\n",
    "male_names = list(set(male_names_list))\n",
    "print(len(male_names))\n",
    "\n",
    "female_names = list(set(female_names_list))\n",
    "print(len(female_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 99, 45, 73, 89, 34, 18, 83, 95, 29]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(range(100), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: JOVENTINA.\n",
      "    ... -> J   |||   [0, 0, 0] -> 10\n",
      "    ..J -> O   |||   [0, 0, 10] -> 15\n",
      "    .JO -> V   |||   [0, 10, 15] -> 22\n",
      "    JOV -> E   |||   [10, 15, 22] -> 5\n",
      "    OVE -> N   |||   [15, 22, 5] -> 14\n",
      "    VEN -> T   |||   [22, 5, 14] -> 20\n",
      "    ENT -> I   |||   [5, 14, 20] -> 9\n",
      "    NTI -> N   |||   [14, 20, 9] -> 14\n",
      "    TIN -> A   |||   [20, 9, 14] -> 1\n",
      "    INA -> .   |||   [9, 14, 1] -> 0\n",
      "Name: DORCAS.\n",
      "    ... -> D   |||   [0, 0, 0] -> 4\n",
      "    ..D -> O   |||   [0, 0, 4] -> 15\n",
      "    .DO -> R   |||   [0, 4, 15] -> 18\n",
      "    DOR -> C   |||   [4, 15, 18] -> 3\n",
      "    ORC -> A   |||   [15, 18, 3] -> 1\n",
      "    RCA -> S   |||   [18, 3, 1] -> 19\n",
      "    CAS -> .   |||   [3, 1, 19] -> 0\n",
      "Name: JAIDETE.\n",
      "    ... -> J   |||   [0, 0, 0] -> 10\n",
      "    ..J -> A   |||   [0, 0, 10] -> 1\n",
      "    .JA -> I   |||   [0, 10, 1] -> 9\n",
      "    JAI -> D   |||   [10, 1, 9] -> 4\n",
      "    AID -> E   |||   [1, 9, 4] -> 5\n",
      "    IDE -> T   |||   [9, 4, 5] -> 20\n",
      "    DET -> E   |||   [4, 5, 20] -> 5\n",
      "    ETE -> .   |||   [5, 20, 5] -> 0\n"
     ]
    }
   ],
   "source": [
    "possible_chars = sorted(list(set(''.join(female_names) + '.')))\n",
    "n_possible_chars = len(possible_chars)\n",
    "def encode(x):\n",
    "    return possible_chars.index(x)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "n_content_block = 3\n",
    "for i, name in enumerate(female_names):\n",
    "    content_block = '...'\n",
    "    name += '.'\n",
    "    if i<3:\n",
    "        print(f'Name: {name}')\n",
    "    for char in name:\n",
    "        encoded_content_block = [encode(c) for c in content_block]\n",
    "        encoded_char = encode(char)\n",
    "        if i<3:\n",
    "            print(f'    {content_block} -> {char}   |||   {encoded_content_block} -> {encoded_char}')\n",
    "        X.append(encoded_content_block)\n",
    "        Y.append(encoded_char)\n",
    "        content_block = content_block[1:] + char\n",
    "    \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "n80th = int(0.8*len(X))\n",
    "n90th = int(0.9*len(X))\n",
    "\n",
    "X_train = X[:n80th]\n",
    "Y_train = Y[:n80th]\n",
    "\n",
    "X_test = X[n80th:n90th]\n",
    "Y_test = Y[n80th:n90th]\n",
    "\n",
    "X_eval = X[n90th:]\n",
    "Y_eval = Y[n90th:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dimensions = 4\n",
    "n_neuros_h1 = 400\n",
    "\n",
    "V  = torch.randn(n_possible_chars, n_dimensions)\n",
    "W1 = torch.randn(n_dimensions * n_content_block, n_neuros_h1) * 0.2\n",
    "b1 = torch.randn(n_neuros_h1) * 0.1\n",
    "W2 = torch.randn(n_neuros_h1, n_possible_chars) * 0.01\n",
    "b2 = torch.randn(n_possible_chars) * 0.1\n",
    "\n",
    "parameters = [V, W1, b1, W2, b2]\n",
    "for parameter in parameters:\n",
    "    parameter.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 1000: 3.2682111263275146\n",
      "epoch: 101 / 1000: 2.1642227172851562\n",
      "epoch: 201 / 1000: 2.066270589828491\n",
      "epoch: 301 / 1000: 1.9836918115615845\n",
      "epoch: 401 / 1000: 1.9301937818527222\n",
      "epoch: 501 / 1000: 1.8660606145858765\n",
      "epoch: 601 / 1000: 1.854499101638794\n",
      "epoch: 701 / 1000: 1.8482017517089844\n",
      "epoch: 801 / 1000: 1.8086493015289307\n",
      "epoch: 901 / 1000: 1.8173540830612183\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 1\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch_i in range(n_epochs):\n",
    "    # Forward Pass\n",
    "    X_vectorized =  V[X_train].view(len(X_train), -1)\n",
    "    \n",
    "    h1 = (X_vectorized @ W1 + b1).tanh()\n",
    "    output = h1 @ W2 + b2\n",
    "\n",
    "    loss = loss_fn(output, Y_train) \n",
    "\n",
    "    # Backprop\n",
    "    for parameter in parameters:\n",
    "        parameter.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    for parameter in parameters:\n",
    "        parameter.data += - learning_rate * parameter.grad\n",
    "    \n",
    "    if epoch_i % 100 == 0:\n",
    "        print(f'epoch: {epoch_i + 1} / {n_epochs}: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 1.8254585266113281\n"
     ]
    }
   ],
   "source": [
    "X_vectorized_test =  V[X_test].view(len(X_test), -1)\n",
    "h1 = (X_vectorized_test @ W1 + b1).tanh()\n",
    "output = h1 @ W2 + b2\n",
    "loss = loss_fn(output, Y_test) \n",
    "print(f'Test: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELY\n",
      "TACI\n",
      "GRACE\n",
      "ZELENE\n",
      "NILSA\n",
      "CEL\n",
      "STEFANE\n",
      "DILLA\n",
      "KELLA\n",
      "ADELA\n",
      "KELE\n",
      "JAULENE\n",
      "ZUANY\n",
      "RAIANE\n",
      "TAYADAIONE\n",
      "ALCE\n",
      "BERMILERILYN\n",
      "LUANA\n",
      "MALINE\n",
      "NELIZALA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/45/871v_dk90997hj5g88_1z7tr0000gn/T/ipykernel_3478/8339307.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities = softmax(out)\n"
     ]
    }
   ],
   "source": [
    "n_names = 20\n",
    "softmax = torch.nn.Softmax()\n",
    "\n",
    "for i in range(n_names):\n",
    "    content_block = '...' \n",
    "    new_name = ''\n",
    "    while True:\n",
    "        start_char_encoded = [encode(c) for c in content_block]\n",
    "        start_char_vector = V[start_char_encoded].view(-1)\n",
    "\n",
    "        h1 = (start_char_vector @ W1 + b1).tanh()\n",
    "        out = h1 @ W2 + b2\n",
    "\n",
    "        probabilities = softmax(out)\n",
    "        next_char_index = torch.multinomial(probabilities, num_samples=1, replacement=True).item()\n",
    "        next_char = possible_chars[next_char_index]\n",
    "\n",
    "        if next_char == '.':\n",
    "            break\n",
    "        else:\n",
    "            content_block = content_block[1:] + next_char\n",
    "            new_name += next_char\n",
    "    print(new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(V, 'V.pt')\n",
    "torch.save(W1, 'W1.pt')\n",
    "torch.save(b1, 'b1.pt')\n",
    "torch.save(W2, 'W2.pt')\n",
    "torch.save(b2, 'b2.pt')\n",
    "with open('possible_chars.txt', 'w') as fp:\n",
    "    for possible_char in possible_chars:\n",
    "        fp.write(possible_char + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
